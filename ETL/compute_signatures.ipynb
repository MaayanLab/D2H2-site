{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import s3fs\n",
    "from maayanlab_bioinformatics.dge import limma_voom_differential_expression\n",
    "from maayanlab_bioinformatics.normalization import quantile_normalize, zscore_normalize\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import contextlib\n",
    "@contextlib.contextmanager\n",
    "def suppress_output(stdout=True, stderr=True, dest='/dev/null'):\n",
    "    ''' Usage:\n",
    "    with suppress_output():\n",
    "        print('hi')\n",
    "    '''\n",
    "    dev_null = open(dest, 'a')\n",
    "    if stdout:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = dev_null\n",
    "    if stderr:\n",
    "        _stderr = sys.stderr\n",
    "        sys.stderr = dev_null\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        if stdout:\n",
    "            sys.stdout = _stdout\n",
    "        if stderr:\n",
    "            sys.stderr = _stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://d2h2.s3.amazonaws.com/'\n",
    "base_url = 'data'\n",
    "s3 = s3fs.S3FileSystem(anon=True, client_kwargs={'endpoint_url': endpoint})\n",
    "\n",
    "version = \"v1.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../app/static/searchdata/metadata-v1.pickle', 'rb') as f:\t\n",
    "\t\tgse_metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sigs(expr_df, metadata_df, species, gse):\n",
    "    \n",
    "    ctrl_conditions = []\n",
    "    metadata_df = metadata_df[metadata_df.index.isin(expr_df.columns.values)]\n",
    "    all_conditions = list(set(metadata_df['Condition'].values))\n",
    "    conditions = []\n",
    "    \n",
    "    # find conditions with replicates\n",
    "    for condition in all_conditions:\n",
    "        if len(metadata_df[metadata_df['Condition'] == condition]) > 1:\n",
    "            conditions.append(condition)\n",
    "\n",
    "    if len(conditions) >= 1:\n",
    "        # identify control conditions or use first condition as default\n",
    "        for condition in conditions:\n",
    "            split_conditions =condition.lower().replace('-', ' ').replace('_', ' ').split(' ')\n",
    "            if 'control' in split_conditions or 'healthy' in split_conditions:\n",
    "                ctrl_conditions.append(condition)\n",
    "\n",
    "        if len(ctrl_conditions) < 1:\n",
    "            ctrl_conditions = conditions\n",
    "\n",
    "        seen = []\n",
    "        for ctrl_cond in ctrl_conditions:\n",
    "            samps_condition = metadata_df[metadata_df['Condition'] == ctrl_cond].index.values\n",
    "            for condition in conditions:\n",
    "                if condition != ctrl_cond and {ctrl_cond, condition} not in seen:\n",
    "                    seen.append({ctrl_cond, condition})\n",
    "                    samps_condition_2 = metadata_df[metadata_df['Condition'] == condition].index.values\n",
    "                    group = list(metadata_df[metadata_df['Condition'] == condition]['Group'].values)[0]\n",
    "                    sig_name = f\"{gse}-{ctrl_cond}-vs-{condition.replace('/', ' ')}-{species}-{group}\"\n",
    "                    if not os.path.exists(f'{species.lower()}/{sig_name}.tsv'):\n",
    "                        try:\n",
    "                            with suppress_output():\n",
    "                                dge = limma_voom_differential_expression(\n",
    "                                    expr_df[samps_condition], expr_df[samps_condition_2],\n",
    "                                    voom_design=True,\n",
    "                                )\n",
    "                            dge.to_csv(f'{species.lower()}/{sig_name}.tsv', sep='\\t')\n",
    "                        except:\n",
    "                            print(\"error computing:\", sig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('human', exist_ok=True)\n",
    "os.makedirs('mouse', exist_ok=True)\n",
    "os.makedirs('signatures', exist_ok=True)\n",
    "os.makedirs(f'signatures/{version}', exist_ok=True)\n",
    "\n",
    "human_done = set(map(lambda x: x.split('-')[0], os.listdir('human')))\n",
    "mouse_done = set(map(lambda x: x.split('-')[0], os.listdir('mouse')))\n",
    "signatures_computed = {'human': human_done, 'mouse': mouse_done}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['human', 'mouse']\n",
    "for species in species_list:\n",
    "    for gse in tqdm(gse_metadata[species]):\n",
    "        if gse not in signatures_computed[species]:\n",
    "            metadata_file = f\"{base_url}/{species}/{gse}/{gse}_Metadata.txt\"\n",
    "            expr_file = f\"{base_url}/{species}/{gse}/{gse}_Expression.txt\"\n",
    "\n",
    "            metadata_df = pd.read_csv(s3.open(metadata_file), sep='\\t', index_col=0)\n",
    "            expr_df = pd.read_csv(s3.open(expr_file), sep='\\t', index_col=0)\n",
    "            expr_df.dropna(inplace=True)\n",
    "            compute_sigs(expr_df, metadata_df, species, gse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "species_list = ['human', 'mouse']\n",
    "\n",
    "for species in species_list:\n",
    "    rna = []\n",
    "    micro = []\n",
    "    for gse in tqdm(gse_metadata[species]):\n",
    "        sig_files = list(filter(lambda x: x.split('-')[0] == gse, os.listdir(species)))\n",
    "        if gse_metadata[species][gse]['type'][0] == 'Expression profiling by array':\n",
    "            for sig in sig_files:\n",
    "                s = pd.read_csv(f'{species}/{sig}', sep='\\t', index_col=0)['logFC'].astype(np.float64)\n",
    "                s.name = sig.replace('.tsv', '')\n",
    "                micro.append(s)\n",
    "        elif gse_metadata[species][gse]['type'][0] == 'Expression profiling by high throughput sequencing':\n",
    "            for sig in sig_files:\n",
    "                s = pd.read_csv(f'{species}/{sig}', sep='\\t', index_col=0)['logFC'].astype(np.float64)\n",
    "                s.name = sig.replace('.tsv', '')\n",
    "                rna.append(s)\n",
    "        else:\n",
    "            print(gse, gse_metadata[species][gse]['type'][0])\n",
    "\n",
    "    micro_df = pd.concat(micro, axis=1)\n",
    "    micro_df.to_csv(f'signatures/{version}/{species}-micro.csv')\n",
    "    micro_df = micro_df.apply(lambda x: np.abs(x))\n",
    "    micro_df_ranks = micro_df.apply(lambda x: x.rank(ascending=False)).T\n",
    "    micro_df_ranks = micro_df_ranks.reset_index()\n",
    "    micro_df_ranks.to_feather(f'signatures/{version}/{species}_micro_fc_signrank.f')\n",
    "\n",
    "    rna_df = pd.concat(rna, axis=1)\n",
    "    rna_df.to_csv(f'signatures/{version}/{species}-rna.csv')\n",
    "    rna_df = rna_df.apply(lambda x: np.abs(x))\n",
    "    rna_df_ranks = rna_df.apply(lambda x: x.rank(ascending=False)).T\n",
    "    rna_df_ranks = rna_df_ranks.reset_index()\n",
    "    rna_df_ranks.columns = (rna_df_ranks.columns.values).astype(str)\n",
    "    rna_df_ranks.to_feather(f'signatures/{version}/{species}_rna_fc_signrank.f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('signature_idx.json') as f:\n",
    "    signature_idx = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and Z-score rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['human', 'mouse']\n",
    "\n",
    "for species in species_list:\n",
    "    for t in ['micro', 'rna']:\n",
    "        df = pd.read_csv(f'signatures/{version}/{species}-{t}.csv', index_col=0).astype('float64')\n",
    "        df = df.loc[signature_idx[f'{species}_{t}']]\n",
    "        df_vals= df.fillna(0)\n",
    "        print('norming')\n",
    "        df = quantile_normalize(df_vals, axis=0)\n",
    "        print('done norming')\n",
    "        df.to_csv(f'signatures/{version}/{t}_{species}_fc.csv')\n",
    "        df.T.reset_index().to_feather(f'signatures/{version}/{t}_{species}_fc.f')\n",
    "        df = zscore_normalize(df)\n",
    "        df = df.apply(lambda x: scipy.stats.norm.sf(np.abs(x)))\n",
    "        df.to_csv(f'signatures/{version}/{t}_{species}_pval.csv')\n",
    "        df.T.reset_index().to_feather(f'signatures/{version}/{t}_{species}_pval.f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
