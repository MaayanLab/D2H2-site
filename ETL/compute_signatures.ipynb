{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import s3fs\n",
    "from maayanlab_bioinformatics.dge import limma_voom_differential_expression\n",
    "from maayanlab_bioinformatics.normalization import quantile_normalize, zscore_normalize\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import contextlib\n",
    "@contextlib.contextmanager\n",
    "def suppress_output(stdout=True, stderr=True, dest='/dev/null'):\n",
    "    ''' Usage:\n",
    "    with suppress_output():\n",
    "        print('hi')\n",
    "    '''\n",
    "    dev_null = open(dest, 'a')\n",
    "    if stdout:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = dev_null\n",
    "    if stderr:\n",
    "        _stderr = sys.stderr\n",
    "        sys.stderr = dev_null\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        if stdout:\n",
    "            sys.stdout = _stdout\n",
    "        if stderr:\n",
    "            sys.stderr = _stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = 'https://d2h2.s3.amazonaws.com/'\n",
    "base_url = 'data'\n",
    "s3 = s3fs.S3FileSystem(anon=True, client_kwargs={'endpoint_url': endpoint})\n",
    "\n",
    "version = \"v1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../app/static/data/metadata-v2.pickle', 'rb') as f:\t\n",
    "\t\tgse_metadata = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sigs(expr_df, all_meta_df, species, gse):\n",
    "    groups = all_meta_df['Group'].unique()\n",
    "    for group in groups:\n",
    "        metadata_df = all_meta_df[all_meta_df['Group'] == group]\n",
    "        ctrl_conditions = []\n",
    "        metadata_df = metadata_df[metadata_df.index.isin(expr_df.columns.values)]\n",
    "        all_conditions = list(set(metadata_df['Condition'].values))\n",
    "        conditions = []\n",
    "        \n",
    "        # find conditions with replicates\n",
    "        for condition in all_conditions:\n",
    "            if len(metadata_df[metadata_df['Condition'] == condition]) > 1:\n",
    "                conditions.append(condition)\n",
    "\n",
    "        if len(conditions) >= 1:\n",
    "            # identify control conditions or use first condition as default\n",
    "            for condition in conditions:\n",
    "                split_conditions =condition.lower().replace('-', ' ').replace('_', ' ').split(' ')\n",
    "                if 'control' in split_conditions or 'healthy' in split_conditions:\n",
    "                    ctrl_conditions.append(condition)\n",
    "\n",
    "            if len(ctrl_conditions) < 1:\n",
    "                ctrl_conditions = conditions\n",
    "\n",
    "            seen = []\n",
    "            for ctrl_cond in ctrl_conditions:\n",
    "                samps_condition = metadata_df[metadata_df['Condition'] == ctrl_cond].index.values\n",
    "                for condition in conditions:\n",
    "                    if condition != ctrl_cond and {ctrl_cond, condition} not in seen:\n",
    "                        seen.append({ctrl_cond, condition})\n",
    "                        samps_condition_2 = metadata_df[metadata_df['Condition'] == condition].index.values\n",
    "                        group = list(metadata_df[metadata_df['Condition'] == condition]['Group'].values)[0]\n",
    "                        sig_name = f\"{gse}-{ctrl_cond}-vs-{condition.replace('/', ' ')}-{species}-{group}\"\n",
    "                        if not os.path.exists(f'{species.lower()}/{sig_name}.tsv'):\n",
    "                            try:\n",
    "                                with suppress_output():\n",
    "                                    dge = limma_voom_differential_expression(\n",
    "                                        expr_df[samps_condition], expr_df[samps_condition_2],\n",
    "                                        voom_design=True,\n",
    "                                    )\n",
    "                                dge.to_csv(f'{species.lower()}/{sig_name}.tsv', sep='\\t')\n",
    "                            except:\n",
    "                                print(\"error computing:\", sig_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('signatures', exist_ok=True)\n",
    "os.makedirs(f'signatures/{version}', exist_ok=True)\n",
    "os.makedirs('signatures/human', exist_ok=True)\n",
    "os.makedirs('signatures/mouse', exist_ok=True)\n",
    "\n",
    "human_done = set(map(lambda x: x.split('-')[0], os.listdir('signatures/human')))\n",
    "mouse_done = set(map(lambda x: x.split('-')[0], os.listdir('signatures/mouse')))\n",
    "signatures_computed = {'human': human_done, 'mouse': mouse_done}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['human', 'mouse']\n",
    "for species in species_list:\n",
    "    for gse in tqdm(gse_metadata[species]):\n",
    "        if gse not in signatures_computed[species]:\n",
    "            metadata_file = f\"{base_url}/{species}/{gse}/{gse}_Metadata.tsv\"\n",
    "            expr_file = f\"{base_url}/{species}/{gse}/{gse}_Expression.tsv\"\n",
    "\n",
    "            metadata_df = pd.read_csv(s3.open(metadata_file), sep='\\t', index_col=0)\n",
    "            expr_df = pd.read_csv(s3.open(expr_file), sep='\\t', index_col=0)\n",
    "            expr_df.dropna(inplace=True)\n",
    "            compute_sigs(expr_df, metadata_df, species, gse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['human', 'mouse']\n",
    "\n",
    "for species in species_list:\n",
    "    rna = []\n",
    "    micro = []\n",
    "    for gse in tqdm(gse_metadata[species]):\n",
    "        sig_files = list(filter(lambda x: x.split('-')[0] == gse, os.listdir(species)))\n",
    "        if gse_metadata[species][gse]['type'][0] == 'Expression profiling by array':\n",
    "            for sig in sig_files:\n",
    "                s = pd.read_csv(f'{species}/{sig}', sep='\\t', index_col=0)['logFC'].astype(np.float64)\n",
    "                s.name = sig.replace('.tsv', '')\n",
    "                micro.append(s)\n",
    "        elif gse_metadata[species][gse]['type'][0] == 'Expression profiling by high throughput sequencing':\n",
    "            for sig in sig_files:\n",
    "                s = pd.read_csv(f'{species}/{sig}', sep='\\t', index_col=0)['logFC'].astype(np.float64)\n",
    "                s.name = sig.replace('.tsv', '')\n",
    "                rna.append(s)\n",
    "        else:\n",
    "            print(gse, gse_metadata[species][gse]['type'][0])\n",
    "\n",
    "    micro_df = pd.concat(micro, axis=1)\n",
    "    micro_df.to_csv(f'signatures/{version}/{species}-micro.csv')\n",
    "    micro_df = micro_df.apply(lambda x: np.abs(x))\n",
    "    micro_df_ranks = micro_df.apply(lambda x: x.rank(ascending=False)).T\n",
    "    micro_df_ranks = micro_df_ranks.reset_index()\n",
    "    micro_df_ranks.to_feather(f'signatures/{version}/{species}_micro_fc_sigrank.f')\n",
    "\n",
    "    rna_df = pd.concat(rna, axis=1)\n",
    "    rna_df.to_csv(f'signatures/{version}/{species}-rna.csv')\n",
    "    rna_df = rna_df.apply(lambda x: np.abs(x))\n",
    "    rna_df_ranks = rna_df.apply(lambda x: x.rank(ascending=False)).T\n",
    "    rna_df_ranks = rna_df_ranks.reset_index()\n",
    "    rna_df_ranks.columns = (rna_df_ranks.columns.values).astype(str)\n",
    "    rna_df_ranks.to_feather(f'signatures/{version}/{species}_rna_fc_sigrank.f')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_sigs = os.listdir('signatures/human') \n",
    "human_sigs_name = list(filter(lambda f: f[0] != '.', map(lambda f: f.replace('.tsv', ''), human_sigs)))\n",
    "mouse_sigs = os.listdir('signatures/mouse')\n",
    "mouse_sigs_name = list(filter(lambda f: f[0] != '.', map(lambda f: f.replace('.tsv', ''), mouse_sigs)))\n",
    "\n",
    "with open('../app/static/data/all_sigs.json', 'w') as f:\n",
    "    json.dump({'human': human_sigs, 'mouse': mouse_sigs_name}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../app/static/data/signature_idx.json') as f:\n",
    "    signature_idx = json.load(f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize and Z-score rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_list = ['human', 'mouse']\n",
    "\n",
    "for species in species_list:\n",
    "    for t in ['micro', 'rna']:\n",
    "        df = pd.read_csv(f'signatures/{version}/{species}-{t}.csv', index_col=0).astype('float64')\n",
    "        df = df.loc[signature_idx[f'{species}_{t}']]\n",
    "        df_vals= df.fillna(0)\n",
    "        print('norming')\n",
    "        df = quantile_normalize(df_vals, axis=0)\n",
    "        print('done norming')\n",
    "        df.to_csv(f'signatures/{version}/{t}_{species}_fc.csv')\n",
    "        df.T.reset_index().to_feather(f'signatures/{version}/{t}_{species}_fc.f')\n",
    "        df = zscore_normalize(df)\n",
    "        df = df.apply(lambda x: scipy.stats.norm.sf(np.abs(x)))\n",
    "        df.to_csv(f'signatures/{version}/{t}_{species}_pval.csv')\n",
    "        df.T.reset_index().to_feather(f'signatures/{version}/{t}_{species}_pval.f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Gene Set Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs_sets = {}\n",
    "for sig in human_sigs:\n",
    "    dge_df = pd.read_csv(f'signatures/human/{sig}', sep='\\t', compression='gzip', index_col=0)\n",
    "    up_genes = dge_df[(dge_df['adj.P.Val'] < .05) & (dge_df['t'] > 0)].index.values[:500]\n",
    "    down_genes = dge_df[(dge_df['adj.P.Val'] < .05) & (dge_df['t'] < 0)].index.values[-500:]\n",
    "    \n",
    "    up_genes = list(filter(lambda g: '.' not in g, up_genes))\n",
    "    down_genes = list(filter(lambda g: '.' not in g, down_genes))\n",
    "\n",
    "    if len(up_genes) >= 5:\n",
    "        sigs_sets[f\"{sig.replace('.tsv', '')} up\"] = up_genes\n",
    "    if len(up_genes) >= 5:\n",
    "        sigs_sets[f\"{sig.replace('.tsv', '')} up\"] = up_genes\n",
    "    print(up_genes, down_genes)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigs_sets = {}\n",
    "for sig in human_sigs:\n",
    "    dge_df = pd.read_csv(f'signatures/human/{sig}', sep='\\t', compression='gzip', index_col=0)\n",
    "    up_genes = dge_df[(dge_df['adj.P.Val'] < .05) & (dge_df['t'] > 0)].index.values[:500]\n",
    "    down_genes = dge_df[(dge_df['adj.P.Val'] < .05) & (dge_df['t'] < 0)].index.values[-500:]\n",
    "    \n",
    "    up_genes = list(filter(lambda g: '.' not in g, up_genes))\n",
    "    down_genes = list(filter(lambda g: '.' not in g, down_genes))\n",
    "\n",
    "    if len(up_genes) >= 5:\n",
    "        sigs_sets[f\"{sig.replace('.tsv', '')} human up\"] = up_genes\n",
    "    if len(down_genes) >= 5:\n",
    "        sigs_sets[f\"{sig.replace('.tsv', '')} human dn\"] = down_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sig in mouse_sigs:\n",
    "    dge_df = pd.read_csv(f'signatures/mouse/{sig}', sep='\\t', compression='gzip', index_col=0)\n",
    "    up_genes = dge_df[(dge_df['adj.P.Val'] < .05) & (dge_df['t'] > 0)].index.values[:500]\n",
    "    down_genes = dge_df[(dge_df['adj.P.Val'] < .05) & (dge_df['t'] < 0)].index.values[-500:]\n",
    "    \n",
    "    up_genes = list(filter(lambda g: (('.' not in g) and (g[:2] != 'gm')), up_genes))\n",
    "    down_genes = list(filter(lambda g: (('.' not in g) and (g[:2] != 'gm')), down_genes))\n",
    "\n",
    "    up_genes = list(map(lambda g: g.upper(), up_genes))\n",
    "    down_genes = list(map(lambda g: g.upper(), down_genes))\n",
    "    \n",
    "    if len(up_genes) >= 5:\n",
    "        sigs_sets[f\"{sig.replace('.tsv', '')} mouse up\"] = up_genes\n",
    "    if len(down_genes) >= 5:\n",
    "        sigs_sets[f\"{sig.replace('.tsv', '')} mouse dn\"] = down_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'D2H2_signatures_{formatted_datetime}.txt', 'w') as f:\n",
    "    for sig in sigs_sets:\n",
    "        gene_str = '\\t'.join(sigs_sets[sig])\n",
    "        f.write(f\"{sig}\\t\\t{gene_str}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
